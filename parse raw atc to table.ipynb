{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","import re\n","import json\n","from datetime import datetime\n","\n","def parse_atc_file_function(file_path):\n","    \"\"\"\n","    Parse the raw ATC from KEGG saves it as JSON with today's date.\n","    \n","    Args:\n","        file_path: Input file\n","        context: Execution context (provided by Airflow or testing)\n","        \n","    Returns:\n","        str: Path to the downloaded file\n","    \"\"\"\n","    result = []\n","    \n","    # Dictionary to store the current hierarchy\n","    current = {\n","        'A': None,\n","        'B': None,\n","        'C': None,\n","        'D': None,\n","        'E': None\n","    }\n","    \n","    # Store ATC codes at different levels\n","    atc_codes = {\n","        'B': None,  # For A01\n","        'C': None,  # For A01A\n","        'D': None,  # For A01AA\n","    }\n","    \n","    current_e_data = None\n","    kegg_entries = []\n","    \n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            line = line.strip()\n","            \n","            # Skip empty lines and header lines\n","            if not line or line.startswith('!') or line.startswith('+F'):\n","                continue\n","            \n","            # Extract depth and content\n","            if line[0] in 'ABCDEF':\n","                depth = line[0]\n","                content = line[1:].strip()\n","                \n","                # Process based on depth\n","                if depth == 'A':\n","                    # New section - reset hierarchy\n","                    current = {\n","                        'A': content,\n","                        'B': None,\n","                        'C': None,\n","                        'D': None,\n","                        'E': None\n","                    }\n","                    \n","                    # Add the top-level entry (e.g., AA)\n","                    result.append({\n","                        'depth': 'A',\n","                        'atc': content[:2].strip(),\n","                        'name': content\n","                    })\n","                    \n","                elif depth == 'B':\n","                    current['B'] = content\n","                    \n","                    # Extract ATC code like A01\n","                    match = re.search(r'([A-Z]\\d{2})\\s', content)\n","                    if match:\n","                        code = match.group(1)\n","                        atc_codes['B'] = code\n","                        name = content[content.find(' ')+1:].strip()\n","                        \n","                        result.append({\n","                            'depth': 'B',\n","                            'atc': code.strip(),\n","                            'name': name,\n","                            'father': code[0]  # Just the first letter (A, B, etc.)\n","                        })\n","                    \n","                elif depth == 'C':\n","                    current['C'] = content\n","                    \n","                    # Extract ATC code like A01A\n","                    match = re.search(r'([A-Z]\\d{2}[A-Z])\\s', content)\n","                    if match:\n","                        code = match.group(1)\n","                        atc_codes['C'] = code\n","                        name = content[content.find(' ')+1:].strip()\n","                        \n","                        result.append({\n","                            'depth': 'C',\n","                            'atc': code.strip(),\n","                            'name': name,\n","                            'father': atc_codes['B']  # Parent like A01\n","                        })\n","                    \n","                elif depth == 'D':\n","                    current['D'] = content\n","                    \n","                    # Extract ATC code like A01AA\n","                    match = re.search(r'([A-Z]\\d{2}[A-Z]{2})\\s', content)\n","                    if match:\n","                        code = match.group(1)\n","                        atc_codes['D'] = code\n","                        name = content[content.find(' ')+1:].strip()\n","                        \n","                        result.append({\n","                            'depth': 'D',\n","                            'atc': code.strip(),\n","                            'name': name,\n","                            'father': atc_codes['C']  # Parent like A01A\n","                        })\n","                    \n","                elif depth == 'E':\n","                    # If we have a previous E entry that hasn't been added to result yet\n","                    if current_e_data and current_e_data not in result:\n","                        if kegg_entries:\n","                            current_e_data['KEGG'] = kegg_entries\n","                        result.append(current_e_data)\n","                    \n","                    # Parse the E line\n","                    atc_code_match = re.search(r'([A-Z]\\d{2}[A-Z]{2}\\d{2})', content)\n","                    if atc_code_match:\n","                        atc_code = atc_code_match.group(1)\n","                        \n","                        # Extract the name (everything after the ATC code and space)\n","                        name_start = content.find(atc_code) + len(atc_code) + 1\n","                        name = content[name_start:].strip()\n","                        \n","                        # Extract DG code if present\n","                        dg_match = re.search(r'\\[DG:(\\w+)\\]', name)\n","                        dg_code = None\n","                        if dg_match:\n","                            dg_code = dg_match.group(1)\n","                            # Remove the DG part from the name\n","                            name = re.sub(r'\\s*\\[DG:\\w+\\]', '', name)\n","                        \n","                        # Extract father code (parent at D level)\n","                        father_code = atc_codes['D']\n","                        \n","                        current_e_data = {\n","                            'depth': 'E',\n","                            'atc': atc_code.strip(),\n","                            'name': name,\n","                            'father': father_code\n","                        }\n","                        \n","                        if dg_code:\n","                            current_e_data['DG'] = dg_code\n","                        \n","                        kegg_entries = []\n","                    else:\n","                        current_e_data = None\n","                        \n","                elif depth == 'F' and current_e_data:\n","                    # Extract KEGG ID and name more carefully\n","                    kegg_match = re.search(r'([A-Z]\\d+)', content)\n","                    \n","                    if kegg_match:\n","                        kegg_id = kegg_match.group(1)\n","                        \n","                        # Get everything after the KEGG ID\n","                        kegg_id_pos = content.find(kegg_id) + len(kegg_id)\n","                        name = content[kegg_id_pos:].strip()\n","                        \n","                        # Replace HTML entities\n","                        name = name.replace('&lt;', '<').replace('&gt;', '>')\n","                        \n","                        kegg_entries.append({\n","                            'kegg_id': kegg_id,\n","                            'name': name\n","                        })\n","    \n","    # Add the last entry if it exists\n","    if current_e_data and current_e_data not in result:\n","        if kegg_entries:\n","            current_e_data['KEGG'] = kegg_entries\n","        result.append(current_e_data)\n","\n","    return result"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"cec34c0c-3697-48ea-b428-aef53aec7004","normalized_state":"finished","queued_time":"2025-10-12T10:34:32.599774Z","session_start_time":null,"execution_start_time":"2025-10-12T10:34:32.6018956Z","execution_finish_time":"2025-10-12T10:34:33.2012874Z","parent_msg_id":"2003327d-dae7-4380-952b-0751d44dc88c"},"text/plain":"StatementMeta(, cec34c0c-3697-48ea-b428-aef53aec7004, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"05208d31-7c01-4d7e-8a30-9a57de489087"},{"cell_type":"code","source":["\n","\n","result = parse_atc_file_function(file_path = '/lakehouse/default/Files/br08303_2025-05-15.txt')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"cec34c0c-3697-48ea-b428-aef53aec7004","normalized_state":"finished","queued_time":"2025-10-12T10:34:32.6427729Z","session_start_time":null,"execution_start_time":"2025-10-12T10:34:33.2038094Z","execution_finish_time":"2025-10-12T10:34:34.1718585Z","parent_msg_id":"53b67de0-0565-47fc-a4a0-2941990d652a"},"text/plain":"StatementMeta(, cec34c0c-3697-48ea-b428-aef53aec7004, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"037350da-821d-4266-8b1d-42128fa5e322"},{"cell_type":"code","source":["df = spark.createDataFrame(result)\n","df.head(5)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"cec34c0c-3697-48ea-b428-aef53aec7004","normalized_state":"finished","queued_time":"2025-10-12T10:34:32.7429866Z","session_start_time":null,"execution_start_time":"2025-10-12T10:34:34.1747985Z","execution_finish_time":"2025-10-12T10:34:35.1067614Z","parent_msg_id":"abdffdb3-7f1e-423d-9e7a-5ddd47f92f8c"},"text/plain":"StatementMeta(, cec34c0c-3697-48ea-b428-aef53aec7004, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"[Row(atc='A', depth='A', name='A ALIMENTARY TRACT AND METABOLISM', father=None, KEGG=None, DG=None),\n Row(atc='A01', depth='B', name='STOMATOLOGICAL PREPARATIONS', father='A', KEGG=None, DG=None),\n Row(atc='A01A', depth='C', name='STOMATOLOGICAL PREPARATIONS', father='A01', KEGG=None, DG=None),\n Row(atc='A01AA', depth='D', name='Caries prophylactic agents', father='A01A', KEGG=None, DG=None),\n Row(atc='A01AA01', depth='E', name='Sodium fluoride', father='A01AA', KEGG=[{'name': 'Sodium fluoride (JAN/USP) <JP>', 'kegg_id': 'D00943'}], DG=None)]"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b65a933c-a834-4de1-b286-dd2e8e812423"},{"cell_type":"code","source":["# Or, if Silver Lakehouse is attached in the UI and named 'SilverLakeHouse':\n","#output_path_silver = \"abfss://drug_atc@onelake.dfs.fabric.microsoft.com/SilverLakeHouse.Lakehouse/Files/br08303_2025-05-15.json\"\n","\n","# It's generally best to write to a *Table* in the Silver Lakehouse as Delta format\n","df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"SilverLakeHouse.atc_codes\")\n","\n","# If you must write a file:\n","#df.coalesce(1).write.format(\"json\").mode(\"overwrite\").save(output_path_silver)\n","\n","print(\"Data successfully processed and written to Silver Lakehouse.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"cec34c0c-3697-48ea-b428-aef53aec7004","normalized_state":"finished","queued_time":"2025-10-12T10:34:32.8104094Z","session_start_time":null,"execution_start_time":"2025-10-12T10:34:35.1091546Z","execution_finish_time":"2025-10-12T10:34:45.9392566Z","parent_msg_id":"f9510200-dd28-4981-8d16-4f1218473ece"},"text/plain":"StatementMeta(, cec34c0c-3697-48ea-b428-aef53aec7004, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Data successfully processed and written to Silver Lakehouse.\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7ecd61a3-9ec8-4313-843b-c4cc5e39bd35"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ef26cfcb-ac0c-4d87-8c58-6a2fa064d583"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"295ee629-3726-43a9-90fe-e9eb104eee94"},{"id":"1a87195f-ef37-4c76-ae81-f136e8f44228"}],"default_lakehouse":"295ee629-3726-43a9-90fe-e9eb104eee94","default_lakehouse_name":"BronzeLakeHose","default_lakehouse_workspace_id":"6eff1b92-5581-46f0-b2fe-fbb6edbc3ff4"}}},"nbformat":4,"nbformat_minor":5}